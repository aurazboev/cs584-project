{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 584 Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Accuracy: 0.5141388174807198\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.00      0.00      0.00         9\n",
      "           2       0.15      0.14      0.14        22\n",
      "           3       0.00      0.00      0.00         8\n",
      "           4       0.00      0.00      0.00        33\n",
      "           5       0.00      0.00      0.00        20\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.00      0.00      0.00        67\n",
      "           9       0.00      0.00      0.00         1\n",
      "          10       0.52      0.67      0.59        82\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.54      0.70      0.61       122\n",
      "          16       0.52      0.59      0.55        27\n",
      "          17       0.45      0.33      0.38        39\n",
      "          18       0.00      0.00      0.00        46\n",
      "          19       0.00      0.00      0.00         2\n",
      "          21       0.00      0.00      0.00        15\n",
      "          22       0.00      0.00      0.00        21\n",
      "          23       0.53      0.89      0.66       255\n",
      "\n",
      "    accuracy                           0.51       778\n",
      "   macro avg       0.13      0.17      0.15       778\n",
      "weighted avg       0.36      0.51      0.42       778\n",
      "\n",
      "-------------------------------------------------------\n",
      "Model: Decision Tree\n",
      "Accuracy: 0.4498714652956298\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.09      0.11      0.10         9\n",
      "           2       0.16      0.23      0.19        22\n",
      "           3       0.15      0.25      0.19         8\n",
      "           4       0.15      0.12      0.14        33\n",
      "           5       0.07      0.05      0.06        20\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.35      0.42      0.38        67\n",
      "           9       0.00      0.00      0.00         1\n",
      "          10       0.56      0.65      0.60        82\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.63      0.61      0.62       122\n",
      "          16       0.68      0.78      0.72        27\n",
      "          17       0.18      0.21      0.19        39\n",
      "          18       0.19      0.15      0.17        46\n",
      "          19       0.40      1.00      0.57         2\n",
      "          21       0.33      0.20      0.25        15\n",
      "          22       0.06      0.05      0.05        21\n",
      "          23       0.59      0.55      0.57       255\n",
      "          24       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.45       778\n",
      "   macro avg       0.21      0.24      0.22       778\n",
      "weighted avg       0.45      0.45      0.45       778\n",
      "\n",
      "-------------------------------------------------------\n",
      "Model: Random Forest\n",
      "Accuracy: 0.512853470437018\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.12      0.11      0.12         9\n",
      "           2       0.12      0.18      0.15        22\n",
      "           3       0.00      0.00      0.00         8\n",
      "           4       0.21      0.09      0.13        33\n",
      "           5       0.10      0.05      0.07        20\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.41      0.43      0.42        67\n",
      "           9       0.00      0.00      0.00         1\n",
      "          10       0.59      0.62      0.61        82\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.62      0.70      0.66       122\n",
      "          16       0.68      0.85      0.75        27\n",
      "          17       0.34      0.26      0.29        39\n",
      "          18       0.32      0.13      0.18        46\n",
      "          19       0.67      1.00      0.80         2\n",
      "          21       0.67      0.13      0.22        15\n",
      "          22       0.00      0.00      0.00        21\n",
      "          23       0.57      0.71      0.63       255\n",
      "          24       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.51       778\n",
      "   macro avg       0.26      0.25      0.24       778\n",
      "weighted avg       0.47      0.51      0.48       778\n",
      "\n",
      "-------------------------------------------------------\n",
      "Model: Gaussian Naïve Bayes\n",
      "Accuracy: 0.19023136246786632\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.50      0.04         2\n",
      "           1       0.00      0.00      0.00         9\n",
      "           2       0.09      0.09      0.09        22\n",
      "           3       0.00      0.00      0.00         8\n",
      "           4       0.06      0.03      0.04        33\n",
      "           5       0.00      0.00      0.00        20\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.00      0.00      0.00        67\n",
      "           9       0.11      1.00      0.20         1\n",
      "          10       0.64      0.20      0.30        82\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.25      0.58      0.35       122\n",
      "          16       0.26      0.30      0.28        27\n",
      "          17       0.47      0.23      0.31        39\n",
      "          18       0.25      0.02      0.04        46\n",
      "          19       0.02      0.50      0.04         2\n",
      "          20       0.00      0.00      0.00         0\n",
      "          21       0.00      0.00      0.00        15\n",
      "          22       0.00      0.00      0.00        21\n",
      "          23       0.37      0.15      0.21       255\n",
      "          24       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.19       778\n",
      "   macro avg       0.12      0.16      0.09       778\n",
      "weighted avg       0.28      0.19      0.19       778\n",
      "\n",
      "-------------------------------------------------------\n",
      "Model: K-nearest Neighbors\n",
      "Accuracy: 0.4601542416452442\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.18      0.22      0.20         9\n",
      "           2       0.12      0.23      0.16        22\n",
      "           3       0.00      0.00      0.00         8\n",
      "           4       0.16      0.09      0.12        33\n",
      "           5       0.25      0.05      0.08        20\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.37      0.45      0.40        67\n",
      "           9       0.00      0.00      0.00         1\n",
      "          10       0.49      0.56      0.53        82\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.56      0.59      0.57       122\n",
      "          16       0.62      0.89      0.73        27\n",
      "          17       0.31      0.26      0.28        39\n",
      "          18       0.18      0.07      0.10        46\n",
      "          19       0.33      0.50      0.40         2\n",
      "          21       0.29      0.13      0.18        15\n",
      "          22       0.00      0.00      0.00        21\n",
      "          23       0.55      0.62      0.59       255\n",
      "\n",
      "    accuracy                           0.46       778\n",
      "   macro avg       0.22      0.23      0.22       778\n",
      "weighted avg       0.43      0.46      0.44       778\n",
      "\n",
      "-------------------------------------------------------\n",
      "Model: Support Vector Machine\n",
      "Accuracy: 0.5141388174807198\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.00      0.00      0.00         9\n",
      "           2       0.00      0.00      0.00        22\n",
      "           3       0.00      0.00      0.00         8\n",
      "           4       0.00      0.00      0.00        33\n",
      "           5       0.00      0.00      0.00        20\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.25      0.04      0.08        67\n",
      "           9       0.00      0.00      0.00         1\n",
      "          10       0.57      0.63      0.60        82\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.52      0.71      0.60       122\n",
      "          16       0.55      0.81      0.66        27\n",
      "          17       0.38      0.38      0.38        39\n",
      "          18       0.50      0.02      0.04        46\n",
      "          19       0.00      0.00      0.00         2\n",
      "          21       0.00      0.00      0.00        15\n",
      "          22       0.00      0.00      0.00        21\n",
      "          23       0.52      0.86      0.65       255\n",
      "\n",
      "    accuracy                           0.51       778\n",
      "   macro avg       0.16      0.17      0.15       778\n",
      "weighted avg       0.40      0.51      0.42       778\n",
      "\n",
      "-------------------------------------------------------\n",
      "Model: Neural Network\n",
      "Accuracy: 0.5411311053984575\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.00      0.00      0.00         9\n",
      "           2       0.19      0.27      0.22        22\n",
      "           3       0.00      0.00      0.00         8\n",
      "           4       0.00      0.00      0.00        33\n",
      "           5       0.00      0.00      0.00        20\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.51      0.34      0.41        67\n",
      "           9       0.00      0.00      0.00         1\n",
      "          10       0.61      0.62      0.62        82\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.58      0.70      0.63       122\n",
      "          16       0.59      0.85      0.70        27\n",
      "          17       0.41      0.31      0.35        39\n",
      "          18       0.33      0.04      0.08        46\n",
      "          19       0.00      0.00      0.00         2\n",
      "          20       0.00      0.00      0.00         0\n",
      "          21       0.00      0.00      0.00        15\n",
      "          22       0.00      0.00      0.00        21\n",
      "          23       0.55      0.86      0.67       255\n",
      "\n",
      "    accuracy                           0.54       778\n",
      "   macro avg       0.18      0.19      0.18       778\n",
      "weighted avg       0.45      0.54      0.47       778\n",
      "\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv('Cleaned_Crimes_2001.csv')  # Adjust the file path as needed\n",
    "\n",
    "# Drop all rows with any missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Convert 'Arrest' and 'Domestic' to numeric if they're not already\n",
    "df['Arrest'] = pd.to_numeric(df['Arrest'], errors='coerce')\n",
    "df['Domestic'] = pd.to_numeric(df['Domestic'], errors='coerce')\n",
    "\n",
    "# Encoding categorical variables\n",
    "le_primary_type = LabelEncoder()\n",
    "df['Primary Type'] = le_primary_type.fit_transform(df['Primary Type'])\n",
    "\n",
    "le_location_desc = LabelEncoder()\n",
    "df['Location Description'] = le_location_desc.fit_transform(df['Location Description'])\n",
    "\n",
    "# Selecting relevant columns\n",
    "features = ['Location Description', 'Arrest', 'Domestic', 'Beat', 'District', \n",
    "            'Ward', 'Community Area', 'X Coordinate', 'Y Coordinate', 'Latitude', 'Longitude']\n",
    "target = 'Primary Type'\n",
    "\n",
    "# Split the dataset\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Scale the features to avoid negative values and help with convergence\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model training and evaluation\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=10000),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gaussian Naïve Bayes': GaussianNB(),\n",
    "    'K-nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Support Vector Machine': SVC(),\n",
    "    'Neural Network': MLPClassifier(max_iter=1000)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print(f\"Model: {name}\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, predictions, zero_division=0))\n",
    "    print(\"-\" * 55)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
