{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 584 Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dj/rtvs0_0j6qbgn80b573d1c440000gn/T/ipykernel_79243/705213052.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Arrest'] = pd.to_numeric(df['Arrest'], errors='coerce')\n",
      "/var/folders/dj/rtvs0_0j6qbgn80b573d1c440000gn/T/ipykernel_79243/705213052.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Domestic'] = pd.to_numeric(df['Domestic'], errors='coerce')\n",
      "/var/folders/dj/rtvs0_0j6qbgn80b573d1c440000gn/T/ipykernel_79243/705213052.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Primary Type'] = le_primary_type.fit_transform(df['Primary Type'])\n",
      "/var/folders/dj/rtvs0_0j6qbgn80b573d1c440000gn/T/ipykernel_79243/705213052.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Location Description'] = le_location_desc.fit_transform(df['Location Description'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Accuracy: 0.32671257702065964\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       121\n",
      "           1       0.00      0.00      0.00      3654\n",
      "           2       0.53      0.59      0.56      8243\n",
      "           3       0.25      0.00      0.00      1722\n",
      "           4       0.00      0.00      0.00        26\n",
      "           5       0.00      0.00      0.00        16\n",
      "           6       0.17      0.05      0.07      4933\n",
      "           7       0.00      0.00      0.00       208\n",
      "           8       0.00      0.00      0.00       831\n",
      "           9       0.18      0.04      0.06      3161\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.00      0.00      0.00       158\n",
      "          12       0.00      0.00      0.00         2\n",
      "          13       0.00      0.00      0.00       127\n",
      "          14       0.00      0.00      0.00        25\n",
      "          15       0.00      0.00      0.00        18\n",
      "          16       0.00      0.00      0.00        30\n",
      "          17       0.00      0.00      0.00      1956\n",
      "          18       0.33      0.67      0.44      1431\n",
      "          19       0.00      0.00      0.00         1\n",
      "          20       0.00      0.00      0.00        14\n",
      "          21       0.00      0.00      0.00       367\n",
      "          22       0.00      0.00      0.00         2\n",
      "          23       0.00      0.00      0.00      2443\n",
      "          24       0.00      0.00      0.00        55\n",
      "          25       0.00      0.00      0.00         2\n",
      "          26       0.00      0.00      0.00       231\n",
      "          28       0.00      0.00      0.00      1558\n",
      "          29       0.00      0.00      0.00       184\n",
      "          30       0.00      0.00      0.00        40\n",
      "          31       0.27      0.83      0.41      8152\n",
      "          32       0.28      0.32      0.29      1673\n",
      "\n",
      "    accuracy                           0.33     41385\n",
      "   macro avg       0.06      0.08      0.06     41385\n",
      "weighted avg       0.23      0.33      0.23     41385\n",
      "\n",
      "-------------------------------------------------------\n",
      "Model: Decision Tree\n",
      "Accuracy: 0.29515524948652894\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.14      0.13       121\n",
      "           1       0.14      0.16      0.15      3654\n",
      "           2       0.42      0.44      0.43      8243\n",
      "           3       0.24      0.24      0.24      1722\n",
      "           4       0.18      0.35      0.24        26\n",
      "           5       0.00      0.00      0.00        16\n",
      "           6       0.22      0.22      0.22      4933\n",
      "           7       0.02      0.02      0.02       208\n",
      "           8       0.14      0.13      0.14       831\n",
      "           9       0.35      0.34      0.34      3161\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.23      0.22      0.22       158\n",
      "          12       0.00      0.00      0.00         2\n",
      "          13       0.06      0.07      0.06       127\n",
      "          14       0.00      0.00      0.00        25\n",
      "          15       0.00      0.00      0.00        18\n",
      "          16       0.18      0.17      0.17        30\n",
      "          17       0.20      0.20      0.20      1956\n",
      "          18       0.49      0.50      0.50      1431\n",
      "          19       0.00      0.00      0.00         1\n",
      "          20       0.25      0.14      0.18        14\n",
      "          21       0.09      0.08      0.09       367\n",
      "          22       0.00      0.00      0.00         2\n",
      "          23       0.16      0.15      0.15      2443\n",
      "          24       0.69      0.60      0.64        55\n",
      "          25       0.00      0.00      0.00         2\n",
      "          26       0.07      0.06      0.07       231\n",
      "          28       0.15      0.13      0.14      1558\n",
      "          29       0.02      0.01      0.01       184\n",
      "          30       0.00      0.00      0.00        40\n",
      "          31       0.40      0.38      0.39      8152\n",
      "          32       0.28      0.25      0.26      1673\n",
      "\n",
      "    accuracy                           0.30     41385\n",
      "   macro avg       0.16      0.16      0.16     41385\n",
      "weighted avg       0.30      0.30      0.30     41385\n",
      "\n",
      "-------------------------------------------------------\n",
      "Model: Random Forest\n",
      "Accuracy: 0.332632596351335\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.09      0.11       121\n",
      "           1       0.15      0.12      0.13      3654\n",
      "           2       0.45      0.52      0.48      8243\n",
      "           3       0.28      0.24      0.26      1722\n",
      "           4       0.32      0.35      0.33        26\n",
      "           5       0.00      0.00      0.00        16\n",
      "           6       0.23      0.22      0.23      4933\n",
      "           7       0.02      0.01      0.02       208\n",
      "           8       0.18      0.14      0.16       831\n",
      "           9       0.35      0.38      0.36      3161\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.11      0.06      0.08       158\n",
      "          12       0.00      0.00      0.00         2\n",
      "          13       0.06      0.04      0.05       127\n",
      "          14       0.00      0.00      0.00        25\n",
      "          15       0.00      0.00      0.00        18\n",
      "          16       0.22      0.13      0.17        30\n",
      "          17       0.22      0.20      0.21      1956\n",
      "          18       0.50      0.58      0.54      1431\n",
      "          19       0.00      0.00      0.00         1\n",
      "          20       0.29      0.14      0.19        14\n",
      "          21       0.12      0.06      0.08       367\n",
      "          22       0.00      0.00      0.00         2\n",
      "          23       0.17      0.13      0.15      2443\n",
      "          24       0.72      0.65      0.69        55\n",
      "          25       0.00      0.00      0.00         2\n",
      "          26       0.10      0.07      0.08       231\n",
      "          28       0.16      0.13      0.14      1558\n",
      "          29       0.02      0.01      0.01       184\n",
      "          30       0.00      0.00      0.00        40\n",
      "          31       0.41      0.47      0.44      8152\n",
      "          32       0.31      0.30      0.30      1673\n",
      "\n",
      "    accuracy                           0.33     41385\n",
      "   macro avg       0.17      0.16      0.16     41385\n",
      "weighted avg       0.31      0.33      0.32     41385\n",
      "\n",
      "-------------------------------------------------------\n",
      "Model: Gaussian Naïve Bayes\n",
      "Accuracy: 0.1546212395795578\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       121\n",
      "           1       0.00      0.00      0.00      3654\n",
      "           2       0.54      0.59      0.56      8243\n",
      "           3       0.06      0.00      0.00      1722\n",
      "           4       0.00      0.00      0.00        26\n",
      "           5       0.00      0.00      0.00        16\n",
      "           6       0.15      0.01      0.02      4933\n",
      "           7       0.00      0.00      0.00       208\n",
      "           8       0.00      0.00      0.00       831\n",
      "           9       0.15      0.33      0.21      3161\n",
      "          10       0.00      1.00      0.00         1\n",
      "          11       0.00      0.00      0.00       158\n",
      "          12       0.00      0.00      0.00         2\n",
      "          13       0.00      0.00      0.00       127\n",
      "          14       0.00      0.00      0.00        25\n",
      "          15       0.00      0.00      0.00        18\n",
      "          16       0.01      0.73      0.02        30\n",
      "          17       0.11      0.08      0.09      1956\n",
      "          18       0.00      0.00      0.00      1431\n",
      "          19       0.00      0.00      0.00         1\n",
      "          20       0.00      0.00      0.00        14\n",
      "          21       0.00      0.00      0.00       367\n",
      "          22       0.00      0.00      0.00         2\n",
      "          23       0.00      0.00      0.00      2443\n",
      "          24       0.00      0.00      0.00        55\n",
      "          25       0.00      0.00      0.00         2\n",
      "          26       0.00      0.00      0.00       231\n",
      "          28       0.00      0.00      0.00      1558\n",
      "          29       0.00      0.00      0.00       184\n",
      "          30       0.00      0.00      0.00        40\n",
      "          31       0.32      0.02      0.05      8152\n",
      "          32       0.04      0.03      0.04      1673\n",
      "\n",
      "    accuracy                           0.15     41385\n",
      "   macro avg       0.04      0.09      0.03     41385\n",
      "weighted avg       0.21      0.15      0.14     41385\n",
      "\n",
      "-------------------------------------------------------\n",
      "Model: K-nearest Neighbors\n",
      "Accuracy: 0.319946840642745\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.09      0.07       121\n",
      "           1       0.13      0.17      0.14      3654\n",
      "           2       0.42      0.57      0.48      8243\n",
      "           3       0.18      0.18      0.18      1722\n",
      "           4       0.44      0.27      0.33        26\n",
      "           5       0.00      0.00      0.00        16\n",
      "           6       0.23      0.22      0.22      4933\n",
      "           7       0.06      0.01      0.02       208\n",
      "           8       0.24      0.11      0.15       831\n",
      "           9       0.33      0.37      0.35      3161\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.04      0.01      0.02       158\n",
      "          12       0.00      0.00      0.00         2\n",
      "          13       0.07      0.03      0.04       127\n",
      "          14       0.00      0.00      0.00        25\n",
      "          15       0.00      0.00      0.00        18\n",
      "          16       0.00      0.00      0.00        30\n",
      "          17       0.21      0.19      0.20      1956\n",
      "          18       0.47      0.61      0.53      1431\n",
      "          19       0.00      0.00      0.00         1\n",
      "          20       0.00      0.00      0.00        14\n",
      "          21       0.17      0.03      0.05       367\n",
      "          22       0.00      0.00      0.00         2\n",
      "          23       0.15      0.07      0.10      2443\n",
      "          24       0.62      0.65      0.64        55\n",
      "          25       0.00      0.00      0.00         2\n",
      "          26       0.15      0.04      0.06       231\n",
      "          28       0.18      0.09      0.12      1558\n",
      "          29       0.00      0.00      0.00       184\n",
      "          30       0.00      0.00      0.00        40\n",
      "          31       0.41      0.40      0.41      8152\n",
      "          32       0.32      0.24      0.28      1673\n",
      "\n",
      "    accuracy                           0.32     41385\n",
      "   macro avg       0.15      0.14      0.14     41385\n",
      "weighted avg       0.30      0.32      0.30     41385\n",
      "\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "years = [2022, 2021, 2020]\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through each year, read the corresponding file and append to the list\n",
    "for year in years:\n",
    "    file_path = f'Cleaned_Crimes_{year}.csv'  # Adjust the file path as needed\n",
    "    df = pd.read_csv(file_path)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames in the list into one\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Drop all rows with any missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Convert 'Arrest' and 'Domestic' to numeric if they're not already\n",
    "df['Arrest'] = pd.to_numeric(df['Arrest'], errors='coerce')\n",
    "df['Domestic'] = pd.to_numeric(df['Domestic'], errors='coerce')\n",
    "\n",
    "# Encoding categorical variables\n",
    "le_primary_type = LabelEncoder()\n",
    "df['Primary Type'] = le_primary_type.fit_transform(df['Primary Type'])\n",
    "\n",
    "le_location_desc = LabelEncoder()\n",
    "df['Location Description'] = le_location_desc.fit_transform(df['Location Description'])\n",
    "\n",
    "# Selecting relevant columns\n",
    "features = ['Location Description', 'Arrest', 'Domestic', 'Beat', 'District', \n",
    "            'Ward', 'Community Area', 'X Coordinate', 'Y Coordinate', 'Latitude', 'Longitude']\n",
    "target = 'Primary Type'\n",
    "\n",
    "# Split the dataset\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Scale the features to avoid negative values and help with convergence\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model training and evaluation\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=10000),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gaussian Naïve Bayes': GaussianNB(),\n",
    "    'K-nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Support Vector Machine': SVC(),\n",
    "    'Neural Network': MLPClassifier(max_iter=1000)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print(f\"Model: {name}\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, predictions, zero_division=0))\n",
    "    print(\"-\" * 55)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
